{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "unlikely-implementation",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "blessed-lexington",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Seed:  999\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f404454df70>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set random seed for reproducibility\n",
    "manualSeed = 999\n",
    "#manualSeed = random.randint(1, 10000) # use if you want new results\n",
    "print(\"Random Seed: \", manualSeed)\n",
    "random.seed(manualSeed)\n",
    "torch.manual_seed(manualSeed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "julian-belgium",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of workers for dataloader\n",
    "workers = 2\n",
    "\n",
    "# Batch size during training\n",
    "batch_size = 128\n",
    "\n",
    "# Spatial size of training images. All images will be resized to this\n",
    "#   size using a transformer.\n",
    "image_size = 1\n",
    "\n",
    "# Size of z latent vector (i.e. size of generator input)\n",
    "nz = 100\n",
    "\n",
    "# Size of feature maps in generator\n",
    "ngf = 64\n",
    "\n",
    "# Size of feature maps in discriminator\n",
    "ndf = 64\n",
    "\n",
    "# Number of training epochs\n",
    "num_epochs = 100000\n",
    "\n",
    "# Learning rate for optimizers\n",
    "lr = 0.0002\n",
    "\n",
    "# Beta1 hyperparam for Adam optimizers\n",
    "beta1 = 0.5\n",
    "\n",
    "# Number of GPUs available. Use 0 for CPU mode.\n",
    "ngpu = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "abstract-female",
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom weights initialization called on netG and netD\n",
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
    "        nn.init.constant_(m.bias.data, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dying-turtle",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generator Code\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, ngpu, input_size):\n",
    "        super(Generator, self).__init__()\n",
    "        self.ngpu = ngpu\n",
    "        self.main = nn.Sequential(\n",
    "            # input is Z, going into a convolution\n",
    "            nn.Linear(input_size, 128, bias=False),\n",
    "            nn.LeakyReLU(0.2),\n",
    "\n",
    "            nn.Linear(128, 128, bias=False),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            \n",
    "            nn.Linear(128, 128, bias=False),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            \n",
    "            nn.Linear(128, 128, bias=False),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            \n",
    "            nn.Linear(128, 6, bias=False),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.main(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "subtle-athens",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if (torch.cuda.is_available() and ngpu > 0) else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "distinct-classroom",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ngpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "subtle-reunion",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generator(\n",
      "  (main): Sequential(\n",
      "    (0): Linear(in_features=50, out_features=128, bias=False)\n",
      "    (1): LeakyReLU(negative_slope=0.2)\n",
      "    (2): Linear(in_features=128, out_features=128, bias=False)\n",
      "    (3): LeakyReLU(negative_slope=0.2)\n",
      "    (4): Linear(in_features=128, out_features=128, bias=False)\n",
      "    (5): LeakyReLU(negative_slope=0.2)\n",
      "    (6): Linear(in_features=128, out_features=128, bias=False)\n",
      "    (7): LeakyReLU(negative_slope=0.2)\n",
      "    (8): Linear(in_features=128, out_features=6, bias=False)\n",
      "    (9): Sigmoid()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Create the generator\n",
    "netG = Generator(ngpu, 50).to(device)\n",
    "\n",
    "# Handle multi-gpu if desired\n",
    "if (device.type == 'cuda') and (ngpu > 1):\n",
    "    netG = nn.DataParallel(netG, list(range(ngpu)))\n",
    "\n",
    "# Apply the weights_init function to randomly initialize all weights\n",
    "#  to mean=0, stdev=0.02.\n",
    "netG.apply(weights_init)\n",
    "\n",
    "# Print the model\n",
    "print(netG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "earlier-chance",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, ngpu, input_size):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.ngpu = ngpu\n",
    "        self.main = nn.Sequential(\n",
    "            # input is Z, going into a convolution\n",
    "            nn.Linear(input_size, 128, bias=False),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(0.1),\n",
    "\n",
    "            nn.Linear(128, 128, bias=False),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(0.1),\n",
    "            \n",
    "            nn.Linear(128, 128, bias=False),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(0.1),\n",
    "            \n",
    "            nn.Linear(128, 128, bias=False),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(0.1),\n",
    "            \n",
    "            nn.Linear(128, 1, bias=False),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.main(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "elegant-heading",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discriminator(\n",
      "  (main): Sequential(\n",
      "    (0): Linear(in_features=2, out_features=128, bias=False)\n",
      "    (1): LeakyReLU(negative_slope=0.2)\n",
      "    (2): Dropout(p=0.1, inplace=False)\n",
      "    (3): Linear(in_features=128, out_features=128, bias=False)\n",
      "    (4): LeakyReLU(negative_slope=0.2)\n",
      "    (5): Dropout(p=0.1, inplace=False)\n",
      "    (6): Linear(in_features=128, out_features=128, bias=False)\n",
      "    (7): LeakyReLU(negative_slope=0.2)\n",
      "    (8): Dropout(p=0.1, inplace=False)\n",
      "    (9): Linear(in_features=128, out_features=128, bias=False)\n",
      "    (10): LeakyReLU(negative_slope=0.2)\n",
      "    (11): Dropout(p=0.1, inplace=False)\n",
      "    (12): Linear(in_features=128, out_features=1, bias=False)\n",
      "    (13): Sigmoid()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Create the Discriminator\n",
    "netD = Discriminator(ngpu, 2).to(device)\n",
    "\n",
    "# Handle multi-gpu if desired\n",
    "if (device.type == 'cuda') and (ngpu > 1):\n",
    "    netD = nn.DataParallel(netD, list(range(ngpu)))\n",
    "    \n",
    "# Apply the weights_init function to randomly initialize all weights\n",
    "#  to mean=0, stdev=0.2.\n",
    "netD.apply(weights_init)\n",
    "\n",
    "# Print the model\n",
    "print(netD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "higher-given",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 50])\n"
     ]
    }
   ],
   "source": [
    "# Initialize BCELoss function\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "# Create batch of latent vectors that we will use to visualize\n",
    "#  the progression of the generator\n",
    "fixed_noise = torch.randn(64, 50, device=device)\n",
    "print(fixed_noise.shape)\n",
    "# Establish convention for real and fake labels during training\n",
    "real_label = 1.\n",
    "fake_label = 0.\n",
    "\n",
    "# Setup Adam optimizers for both G and D\n",
    "optimizerD = optim.Adam(netD.parameters(), lr=lr, betas=(beta1, 0.999))\n",
    "optimizerG = optim.Adam(netG.parameters(), lr=lr, betas=(beta1, 0.999))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "mental-intellectual",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_prep_torch import u_v_model, gen_events, get_dsigma1, get_dsigma2, wrapperGenerator, paramsToEvents\n",
    "from scipy.special import gamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "coral-floor",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ground Truth parameters:  [ 2.1875  -0.5      3.       1.09375 -0.5      4.     ]\n"
     ]
    }
   ],
   "source": [
    "# outputDirectory = \"/work/data_science/kishan/Theory/Experiments_0/\"\n",
    "beta=lambda a,b: gamma(a)*gamma(b)/gamma(a+b)\n",
    "\n",
    "au=-0.5; bu=3; nu=2/beta(au+1,bu+1)\n",
    "ad=-0.5; bd=4; nd=1/beta(au+1,bu+1)\n",
    "truth_par=np.array([nu,au,bu,nd,ad,bd])\n",
    "print(\"Ground Truth parameters: \", truth_par)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "spectacular-acrobat",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.7292, 0.2500, 0.6000, 0.3646, 0.2500, 0.8000],\n",
      "        [0.7292, 0.2500, 0.6000, 0.3646, 0.2500, 0.8000]])\n"
     ]
    }
   ],
   "source": [
    "truth = np.array([[2.1875, -0.5, 3, 1.09375, -0.5, 4],\n",
    "                 [2.1875, -0.5, 3, 1.09375, -0.5, 4]]).astype(np.float32)\n",
    "parmin = np.array([0.0, -1.0, 0.0, 0.0, -1.0, 0.0]).astype(np.float32)\n",
    "parmax = np.array([3.0, 1.0, 5.0, 3.0, 1.0, 5.0]).astype(np.float32)\n",
    "\n",
    "def normalize_pars(t, parmin, parmax):\n",
    "    return (t - parmin) / (parmax - parmin)\n",
    "\n",
    "truth_scaled = normalize_pars(truth, parmin, parmax)\n",
    "truth_scaled = torch.from_numpy(truth_scaled)\n",
    "parmin = torch.from_numpy(parmin)\n",
    "parmax = torch.from_numpy(parmax)\n",
    "print(truth_scaled)\n",
    "train_events, train_norm1, train_norm2 = wrapperGenerator(truth_scaled, parmin, parmax, 100000)\n",
    "train_events = train_events[0]\n",
    "train_norm1 = train_norm1[0]\n",
    "train_norm2 = train_norm2[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "opponent-indonesian",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 100000])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_events.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "adapted-academy",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAzgAAAJaCAYAAADjx+JnAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAA55UlEQVR4nO3de7xcZX0v/s8DAbmoKBAuRZG7QRRQgoLCManEW9VDa3+CCoiXQ6WVX0WrNOUcr6USabWn/XlLtVKwSE/PsVoq4KECtdJgidYLCIYWAYUaAq0gEC6B5/fHzA4rm72T2ZfJ3nnyfr9e85rZz6zLd2atPXs++1nrWaXWGgAAgBZsMdMFAAAATBcBBwAAaIaAAwAANEPAAQAAmiHgAAAAzRBwAIBZq5Ty1JmuYWMppTxlpmuAFgg4MI1Kz7GllP9VSrmllLK6lPJAKeW2UsrlpZSzSikvLKWUma51mEopny6l1M7t5pmuaSpKKe8c9XpqKWWvma5rc9L/Peq+/x8Y9fzvlVLuLqX8fzNU4kgdW5ZSvlxK+c9Sygmd9itH1X/lDNb45FLKP5ZS7iilHDNTdWxIKWWPUsoFSS7s/zz6d3CDtxmu/+ej6jl3gNneUUr5p1LK84ddH7RMwIFpUkrZJckVSf4mya8lOT/JwUl2S/KyJNckeW+Sq5L81gyVubG8I73XPCGllJNn6gtgKeUD6/ki8qdJtt2Y9cxWpZQFMxRcd0jyhXFqemKSDyV5cpLfKqXMm8wKpinAvjTJf03ylCR/OKr9lEkuc0JKKeeOFwT73pjkqCRzk/z+xqhpokopL01yXZIXJjmt89TL0vtd3DaP/4yZt57nZsKuSc6a4Dx/nOS+JMtKKe+d9opgMzFnpguAFpRStk1ySZLn9Zt+r9b60c4kP09yRinljvS+9DT9u1drXVNKeWim65gutdZHkjzSeMfbrFZrfbCU8shM1zFZtdaHSikPz3Qdm4JSyouT/F2SrZK8pta6ovP0Q7XWB/rTjf6MeXA9z210/X12zQTnubeU8rokNyVZUkqptdZzhlMhtEsPDkyPd+axcPOLJP9znOn+NMl/bIyCYHNRa703yfuS3JPkk7XWG2awnP+b5Cvp/VPjPTNYx/r8ZXo9yauS/PcZrmUdpZTt0qtvqyRX1lq/0Xn6V5NcO+Ciru1Pv8mptf5nkpFDLT9SSnnOTNYDm6Raq5ub2xRvSW5OUvu3SzYw7XOTPL3/eEFnvpHba5J8JsnKJI8mubkz7zOT/Hl/fQ8muTu9Lyq/kWSLznTXjlrmuf32k0e1d5f9gTFqOSzJ19MLbXcl+esku4zxmo5M8vf96e5P8g9J3j3Wetbzvlw5xvpHbgvGqL321/tX6YXG2l/GvaOm+cA4r+/Kcbbf6Ntenem67b+W5NL+Nrg7ydeS7DuBfaYk+W9JlqX3xfzBJCuSLEmywzjbqyapnWWc22n/10GXO9ntPWp9o28n96fZOsmZSb6b3qE2DyX59yTfTPKxbg3reW+26O8/N/TrX5nk0/1tPXq77jVeLf3nn9x/7dcnWZ3kgSQ/TXJ5ko/0368x3+es+7szuv2D6R1y+m9J1oysd4zpuvtP9/lv9Nd/W/89+rf0DrPbuj/tzut5j0dvh3PH2Ucft9+Mtd3HeP8H/ZwZXcfNSRYluTq9z4F/T/JnSZ44gd+L0zrLe88Gpl0w3nvdmeap6R0mdm2/pvv7j89K8tQN/D48M8nF6f0ejX6fX51emL2r/x79NL3PvTOT7DHOcr+Q5P39bf1gkn9Nbz8vY9R9RGe+/zWVv09ubpvjbcYLcHPb1G9Jnj7qj+KfTmDeLZJsk+SWUV8S3pxkxyTnpB8O+l8c7utP83f99b6q/4eyJvlqkjn9abdO79j60V/StkzvXIC16+rUMqf/B737Wv6qv57jOm2XjHoNR6X3pbEm+XGSg5IcmuTWsdaznvdi6/S+mHe/AG7Tv23Rr32bUfXd0H8PdkryxfQCzhPSO/9p9BfhOaOWf2Vn3U8Y9X6d31l36UzXXfc/J9m3//pHvuBem84XwPW81tKvt/a330uS7JfeF56R5Typ/5oP7azzwSS7dZazVXph+HP992+g5U52e/fX191/bum8T1v2p/l0/7lHkvx6euei7N2vsSbZb4D35xOddXwmye7pnbf26BjbtfTX/43Ocyd3lnVpv+3uJL+c3rk8B6b3O1T778NY+9Yz+21b9ZezTdbdr37Sr3NuemG39veH0cvZq1PLyZ32R5N8OL1z9D7Yaf+bzvRjvq7+dnjc7/c4df7+yDYab7uPeu8n8jkzen94oL/9d0/yO532T03gM/EfO/O9cgPTLhjvve4/v0d6h3qNfDY9J8mzOm03pR9Gxnpf0jtv8kX9bXRlHvsc/VBnmq+mtz/tll6QHr3/faAz7Zr0QuIuSf53p/24MV7bE0e9r9vOxN83N7dN9TbjBbi5beq3JM8f9UfxrEks4+bO/P+7075nel8Mt03ys840z+tM87ed9tM77d0/rOd22rtfCm4eVcdeo17L/M5zd3fa53bar+m0v6vTfuZ461nP+3ByZ54rx5mmW98fdtoPT/KR/uNzO9N8YJDlj/d+rWfdv95p/16n/fABXufxY9UxqoYPddqXd9p/o9O+dXr/QT56ksudzPYed/8ZNd9/pv9FuN8+J71DovbZwHvz7FE17dR57saxtmv/uSs7z53cb9ux03btqOl3Ta9HZ8txtu9eY9TW3a9+Nur1/WX6vV3jLWfU/veLPBae5vR/Hnnupet7XRvaXzPO/j/edu+0T+Zzprs/PNp5D57aab93wN//LfJYuKpJnruB6bvrftw2G1Vz97PpXZ32r6zn9+Edned+Jb1DkQ/vPP9wkqd0pinp9RSOt52u7bT/aqf9q+O8vns60zx/kPfQzc2td3MODky/OrqhPyTrnZ3bd9Yz/1fXLqjWW2utb03vv6S7dqZZMc7jEydb9Dh+1Hn8887jvZKklLJbkvnj1PLDaa5lLN336ppa6+KNsM4R631vNuD1ncc/7Ty+rfP42M7jv+g8flPn8avSCxTfnORyR5vKaxoxclL1U5JcU0r53VLKc2uta2qtc2utN21g/ld1Ht9Va72r8/NE96nuSf0HlVK+UUr57VLKM2utK2ut29beABKT8bVa69oTyGutb6y13jGB+f+t1vpwf9416R22NOJVY88ydFP9nPnPznvw80779qWUuQOs/6lJtuv8fO8A84ypf+2cX+k0jfdaXrWe6+x0P1++Wmv94yQndJ6/odb68840Nclvpnc431gm+vvVff1PG2caYAwCDkzdv4/6+cljTPPrSU5N71CqndL7z/J4bh+j7Zmdx7X2Tqoe8YtxppuyWmt32d3gtn3/fq9Rs9zTeXz3dNYyjrHeq41lQ+/N+hzQefzrI8E3vXNURuzbefzFPPZl/chSysj8JyU5v//FajLLXccA23sQ53ceH5reeSbfKaX8WynlDQPMv1fn8T2jnpvQPtV/PV/pNB2d3jC8N5RSvtcfiniyprrvjX4t3fd+7ykue7Km+jmzdprOPjlikH1o9FDsExqBbJT9s+53nO6+1H0tW6R3GOdYxtrG3d+xO0c/WWu9otZ64zjLm+jvV/f1G6YeJkDAgSmqtf4kvXMRRjzuC2StdWV6h+cM4sHpqGsz0cJ79ZX0gsCh6R3L//T+be0XqVrrnen8NznJSaWUnZO8Isl5k13ukLwrvRPFR492tU+Svyyl/PKQ1z/acemNsDa65+jgJBdN9po5mf59zxjkjw+0W81IFX211rG2cTeYDHubbd15PPq9AdZDwIHp8ZnO4xeVUrYed8rJ6R7aUPoXNhzxpM7j7vC493Ued3/Xd5jGun486udu79V0rmeiNsZrn4ru4Ujb1Fp/2r2l14sxOoh0D1M7Mb2LNS6vtXaXNZnlTrdnJflMrfU56QWq38i6vZyv2cD83X1qdG/ohLZfKWWLJPNqrR+ute6b3n/1fyePfVncOsnLJ7LMaTT6tXR/j7vvwcbclyfzOTNtaq33JOke5jfeoWODuDG9c4JGdPel7mt5tD/toLqHt+08+slSyqGdHtapeso46wU2QMCB6fHHSf6l/3iH9A5Hm07/N72Tf0ccMM7j7n/zb+48fkrn8YHTVVS/Z+qaTlP30JVnTWKRD3Qez0mSUsohpZRzJ7icmzuPn9J5vL7XPta6jymlDOMie3/deXx4KWXLkR9KKVuld0ja0aPm+WoeOyRmz/ROXh7dezOZ5U7UWO/TL5VSLiylPCm9k+JfniT9YLU0ydmdeTZ0scu/6zzeqZSyU+fnie5T2yX57sh1RGqt/1pr/aP0Bu4Yq57uf+xHXtunSykvmOB6B7FPf5uklDInvR6uERd1Ht/cefyUzuOJ7suvL6W8dwM1TeZzZrp1r3vzjMkupPauJdPdl8Z7LX/bPY9mABd0Hj+ze/5OKWVk1LtFE1jemPrnNz6h/+PPMrEQBps9AQemQa11dXqHC438cf5o/+TqPUspO5VSjsq6F/27Pun9i7T/R7F7qMPW/bbRyz8xvVGfkuRDpZSnlVJ+JcnL+m0X5bGLwyW96zeMfCE+opRyYCnl4Kx7gnAppWxTStmi/yXrCVn3yW3WU+PI4SOnp3cdjyR5RynloP56ThlrPVm/73ce79v/I//WJM/u17jNqOmfUEp5Qh7vwk5Ni/rb4b9k3ZO3txh5fWOs+1n9Q8B+M8nepZQtx1n3Fv31d1/XVgP04H0hve2T9IbU/XQp5RmllL2TfD69a3V8ojtD/4T0L3aatk1vWOdJLXcK2/uGPPbe7lJK2Se93qSXdM7h+ZNSyqJSylP7/81+bb/94az7BfFxaq3XJflkp+kPSim7l1JOzbqHf84ppTyhU+/obdA9vOm8UsqRpZQdSimH5LFem7uTfLkzXXcfOLyU8sL0hha/v7+dt+w8P2f0Pr2e/WTL/j7RrWm7JP+9v4//j/SGBU6SL9daL+vW3nn8mlLKrqWUX01v9MYRo9fbfR2HlFJ2SfLb6W2v8bb7FhP9nOm/x1uvu6h19qHR78OcbNi5ncfPG2+i/vYY/Xv2hFHr/c08FhBPK6U8p5TyrCTv6Lfd1J8m/X8GjPW+rLOOWus/pze8d9ILj+eVUvYrpTw9vWv+3Jb+eWj9GruvectSytb9dY31vnX34e7gLX9Ra+32RgEbMtPDuLm5tXRL70vhsen9J/2W9L4oPJjeyapXpHf9hOd2pt8r6w5L+rihW0ctf156X1RvTe9L5j1J/imjLsDXmf6w9Eb0uTe94YS/mHWHEh65LcjYF7qr66nx3M56jkzvApH3pvcl+ptZ9zoYa9czwHv4O+l98Xg4vf9EX5Pel7kF49Rx8zjLeWl6vWqr0/sP6Kez7kUE1xlatr/tzklv9LE16R0adGV6X6pPHmfdCzL2RUKvHOB1zklv2Nnl/fftvvQOEfpYOte6GWN7jqzjr6ey3Clu7xPTG9HswfT2w2vTv2ZJf7l/n951Yu7vb8efJvk/SV4w4O/RFv394Ef95a9K78vj/xq97ddXb3qB4o/Tu7bK7f16H0zvELDz0jt8rbve+Xns92VN/zX8bv+5sbbzOvv0evaTk/P4C9n+Q3pflEcu9Pnj/s9bj/F+nNB5v3+SXo/YWaPX05l+m/Qu1LkyvesR3ZNeMNl5Pdu9+zoG+pzJ+Bd+HW+bfGDA7X95f/qb0h9Ke4xpxtseddR0T03yB0muS++zYHX/8VlZd4jn8bbdmL/L6Y3Qdkl6/0R6qF/PZ5L80gZqvHI96+pugwv7bSvTuSCpm5vbYLdSaw0AwGxQStk1ybL0RpN7d631YxuYpSmllMOTfCu9MPayWus3NzALMIpD1ACAWaP2zu07Mr2enHNKKW+Z4ZI2mlLKYUkuTa9Hb4FwA5Mj4AAAs0rtXYj1Jemd33XwTNezEc1P8tEkz661XrOhiYGxOUQNAABohh4cAACgGQIOAADQjEHGpJ+SnXfeue61117DXg0AALAJ+/a3v31nrXXuVJcz9ICz1157Zfny5cNeDQAAsAkrpdwyHctxiBoAANAMAQcAAGiGgAMAADRDwAEAAJoh4AAAAM0Y+ihqAAAwE+65557ccccdefjhh2e6lM3eVlttlV122SVPfvKTh74uAQcAgObcc889WblyZfbYY49su+22KaXMdEmbrVprVq9endtuuy1Jhh5yHKIGAEBz7rjjjuyxxx7ZbrvthJsZVkrJdtttlz322CN33HHH0Ncn4AAA0JyHH34422677UyXQce22267UQ4XFHAAAGiSnpvZZWNtDwEHAABohoADAACbgC996Ut53vOeN9NlrOMLX/hCnvrUp+bcc8+d6VLWMooaAACbjY9ftmKjru/0RQdM27J23HHHHHDA9C1vKh5++OG8/vWvz9y5c/Pzn/98pstZhx4cAADYBCxYsCAXXnjhTJeRpBdwTjnllHzqU5+a6VIeR8ABAIBZ5IILLsjhhx+ehQsX5sgjj8zixYtz2WWX5YgjjkgpJTfffPPaaZctW5ZDDjkkhx12WF7xilfkYx/7WEopWbBgQX70ox/lzW9+c3bbbbecdNJJOeOMM3L00UfnoIMOyjXXXJPLL788xx57bPbbb7+cffbZ69Tw6U9/Oi94wQuycOHCHH744TnrrLNSa137/HbbbZeXvvSlG+stmRCHqAEAwCxx++2356STTsqKFSuyzz77ZNWqVZk3b14+8pGPZP/998/ee++9dtp77703r371q7N48eK8+93vzv3335+XvOQlSZIrr7wySfL5z38+J598ci666KJ861vfypIlS3LmmWfmLW95S0499dR8+ctfzg033JCDDjooxx133Nrln3feeVm6dGkOOeSQ3HfffXnhC1+Ypz/96TnppJM2+nsyUXpwAABglli5cmUeeeSRtb00c+fOzcUXXzzmtBdccEF+8Ytf5NRTT03S61V529veNua0z33uc7PffvslSV70ohfl2muvzWte85okybx587Ljjjvme9/73trpL7zwwhxyyCFJku233z6vfOUrc8kll0zLaxw2PTgAADBLHHrooTnxxBNzzDHHZMGCBTn++OPzxje+ccxpr7/++uy6667Zbrvt1rbtueeeY067++67r308Mn23bfvtt8/dd9+99uef/OQnOe2003LnnXdmq622ys0337xO79FspgcHAABmiVJKzjvvvPzgBz/IYYcdljPPPDOHHnrowCOVjXcxzS233HKDbSPn2Nxyyy1ZtGhRjjzyyFx11VW58sorc/LJJ69zDs5sJuAAAMAscdttt2XZsmU56KCDcs455+S6667L7bffnq9//euPm/bAAw/MypUrc//9969tu/XWW6dcw/Lly7N69eocd9xxa9seeuihKS93YxFwAABglrjxxhtzxhlnZM2aNUmSRx99NLXW7L///o+b9g1veEOe9KQn5ZOf/GSSZPXq1Tn//POnXMO8efNSSlkbqh544IFceumlU17uxiLgAADALDFv3rzsu+++OfLII7NgwYK8+tWvzic+8YmsXLkyxx9/fJLk+OOPzze/+c088YlPzEUXXZTzzz8/hx12WI4//vi87nWvy5w5j51mf9ppp+XSSy/NpZdemve+9725/PLL8853vjNJ77o6//Ef/5GXvvSl+dnPfpazzz47n/vc53LQQQflU5/6VM4666wcffTROfHEE7PPPvvku9/97toakuQ3f/M3s2DBgiTJ2WefnQULFkxLD9JUlWEfSzd//vy6fPnyoa4DAAC6rr/++hx44IEzXcbQrVq1KnPnzl378wUXXJD3v//9ufHGG2ewqvGtb7uUUr5da50/1XXowQEAgE3UUUcdlTvuuCNJ8uCDD+azn/1sTjjhhBmuamZtfsNEX/GRyc23cPH01gEAAFN07LHH5mUve1l22GGHrF69Osccc0wWL968v7dufgEHAAAasWTJkixZsmSmy5hVBgo4pZRzkxyV5N5RTz01yW5JnlJrXT29pQEAAEzMRHpw3lZrvbLbUEr5TIQbAABglhg04HwmyU3dhlLK9kmOT/Jr010UAADAZAwUcGqty8Zofl2SO5JcPq0VAQAATNJUhon+b0n+rA77QjoAAAADmtQoaqWUZyU5LMmx01oNAADAFEy2B+dtSb5Sa71jrCdLKaeUUpaXUpavWrVq8tUBAABJki996Ut53vOeN9NlJEm+//3v501velNe/OIX5+ijj84LXvCC/M3f/M1Ml5VkEj04pZStk5yY5PXjTVNrXZpkaZLMnz/fIWwAAMwOk73o+2RN48Xid9xxxxxwwAHTtryp+NCHPpSdd945V1xxRbbYYotccskledWrXpWvfe1rOeaYY2a0tsn04Byb5O4kX5/eUgAAgPEsWLAgF1544UyXkSTZd9998+53vztbbNGLE694xSsyb968fPGLX5zhyiYXcN4WgwsAAMBQXHDBBTn88MOzcOHCHHnkkVm8eHEuu+yyHHHEESml5Oabb1477bJly3LIIYfksMMOyyte8Yp87GMfSyklCxYsyI9+9KO8+c1vzm677ZaTTjopZ5xxRo4++ugcdNBBueaaa3L55Zfn2GOPzX777Zezzz57nRo+/elP5wUveEEWLlyYww8/PGeddVa6X/+XLFmS/ffff515tt122zz44INDfW8GMaFD1Eopz0jyX5KcMJxyAABg83X77bfnpJNOyooVK7LPPvtk1apVmTdvXj7ykY9k//33z95777122nvvvTevfvWrs3jx4rz73e/O/fffn5e85CVJkiuvvDJJ8vnPfz4nn3xyLrroonzrW9/KkiVLcuaZZ+Ytb3lLTj311Hz5y1/ODTfckIMOOijHHXfc2uWfd955Wbp0aQ455JDcd999eeELX5inP/3pOemkk8as+5577sl1112X973vfcN9gwYw0R6ctya5aLzBBQAAgMlbuXJlHnnkkbW9NHPnzs3FF1885rQXXHBBfvGLX+TUU09Nkmy33XZ529veNua0z33uc7PffvslSV70ohfl2muvzWte85okybx587Ljjjvme9/73trpL7zwwhxyyCFJku233z6vfOUrc8kll4xb90c/+tEcc8wxa5c5kybUg1NrnflIBgAAjTr00ENz4okn5phjjsmCBQty/PHH541vfOOY015//fXZdddds912261t23PPPcecdvfdd1/7eGT6btv222+fu+++e+3PP/nJT3LaaaflzjvvzFZbbZWbb755nd6jrosvvjgXXXRRvvGNbwz+QodoKhf6BAAAplEpJeedd15+8IMf5LDDDsuZZ56ZQw89ND//+c8Hnn8sW2655QbbRs6xueWWW7Jo0aIceeSRueqqq3LllVfm5JNPzlin4F911VVZvHhxLr300uywww4D1ThsAg4AAMwSt912W5YtW5aDDjoo55xzTq677rrcfvvt+frXHz+A8YEHHpiVK1fm/vvvX9t26623TrmG5cuXZ/Xq1TnuuOPWtj300EOPm+473/lO3v72t+dv//Zv1/YGLV26dMrrnyoBBwAAZokbb7wxZ5xxRtasWZMkefTRR1NrfdyIZUnyhje8IU960pPyyU9+MkmyevXqnH/++VOuYd68eSmlrA1VDzzwQC699NJ1pvnhD3+4doCDVatWZfny5Vm+fHkuuOCCKa9/qiZ8oU8AAGA45s2bl3333TdHHnlktt9++9x33335xCc+kZUrV+aUU05Jkhx//PH5wz/8wxx11FG56KKL8va3vz1f/OIX87SnPS2ve93r8s1vfnPt8k477bS14eS9731vXv7yl+dd73pXkt51db70pS/l+OOPz89+9rOcffbZeeSRR/LWt741n/rUp3LWWWflL/7iL7Lbbrtln332yd///d/n+OOPz4UXXpjf/u3fzu233/6484Ne/OIXb6R3anxl2JezmT9/fl2+fPlQ1zEhk7167TRehRYAgOG6/vrrc+CBB850GUO3atWqzJ07d+3PF1xwQd7//vfnxhtvnMGqxre+7VJK+Xatdf5U1+EQNQAA2EQdddRRueOO3hVcHnzwwXz2s5/NCSds3pesdIgaAABsoo499ti87GUvyw477JDVq1fnmGOOyeLFm/eRRwIOAABsopYsWZIlS5bMdBmzikPUAACAZgg4AABAMwQcAACa9Oijj850CXRsrO0h4AAA0Jztt98+t912Wx566KEM+7IorF+tNQ899FBuu+22bL/99kNfn0EGAABoztOe9rTceeedueWWW7JmzZqZLmezN2fOnOywww7Zeeedh7+uoa8BAAA2si222CK77LJLdtlll5kuhY3MIWoAAEAzBBwAAKAZAg4AANAMAQcAAGiGgAMAADRDwAEAAJoh4AAAAM0QcAAAgGYIOAAAQDMEHAAAoBkCDgAA0AwBBwAAaIaAAwAANEPAAQAAmiHgAAAAzRBwAACAZgg4AABAMwQcAACgGQIOAADQDAEHAABohoADAAA0Q8ABAACaIeAAAADNmDPTBWxsy266a1LzHblwmgsBAACmnR4cAACgGQIOAADQDAEHAABohoADAAA0Q8ABAACaIeAAAADNEHAAAIBmCDgAAEAzBBwAAKAZAg4AANAMAQcAAGiGgAMAADRDwAEAAJoh4AAAAM0QcAAAgGYIOAAAQDMEHAAAoBkCDgAA0AwBBwAAaIaAAwAANEPAAQAAmiHgAAAAzRg44JRSXltK+UYp5dullJtKKctLKScOszgAAICJGCjglFJOT3JmkjfUWg9L8swkK5K8ZIi1AQAATMicDU1QStkrydlJjqq1/jRJaq0Pl1J+J8kvDbc8AACAwW0w4CQ5McnPa63XdBtrrbcnuX0oVQEAAEzCIIeovTDJzf1zcP6xlHJDKeWfSilvGXZxAAAAEzFID87Tk+yV5HeS/GqSO5K8NskXSym711rPGl55AAAAgxukB2ebJNsneU+t9We11kdrrX+d5CtJfq+Ust3oGUopp/RHWVu+atWqaS4ZAABgbIMEnF/07787qv1fkmyX5FmjZ6i1Lq21zq+1zp87d+7UKgQAABjQIAHnhnGmfWQCywAAABi6QcLJRf37g0e1PzvJ6iTXTWtFAAAAkzTIIAN/leSdSX6/lPKqWuu9pZSjk/x6kg/VWu8bZoGzxhUfmfg8CxdPfx0AAMC4Nhhwaq2PlFJenmRJkutKKQ8keTDJO2qtfzbsAgEAAAY1SA9Oaq3/keS/DbkWAACAKTFAAAAA0AwBBwAAaIaAAwAANEPAAQAAmiHgAAAAzRBwAACAZgg4AABAMwQcAACgGQIOAADQDAEHAABohoADAAA0Q8ABAACaIeAAAADNEHAAAIBmCDgAAEAzBBwAAKAZAg4AANAMAQcAAGiGgAMAADRDwAEAAJoh4AAAAM0QcAAAgGYIOAAAQDMEHAAAoBlzZrqATcWym+6a8DxXr1mR0xcdMIRqAACAsejBAQAAmiHgAAAAzRBwAACAZgg4AABAMwQcAACgGQIOAADQDAEHAABohoADAAA0Q8ABAACaIeAAAADNEHAAAIBmCDgAAEAz5sx0AS074talyRU7TXzGhYunvxgAANgM6MEBAACaIeAAAADNEHAAAIBmCDgAAEAzBBwAAKAZAg4AANAMAQcAAGiGgAMAADRDwAEAAJoh4AAAAM0QcAAAgGYIOAAAQDMEHAAAoBkCDgAA0AwBBwAAaIaAAwAANEPAAQAAmiHgAAAAzRBwAACAZgg4AABAMwQcAACgGQIOAADQjDmDTFRK2SvJtUn+dYynF9Rafz6NNQEAAEzKQAGnb3mtdcGwCgEAAJgqh6gBAADNEHAAAIBmTCTg7FpK+UIp5Z9LKStKKReUUp4ztMoAAAAmaNCA80iSNUk+Xmt9fpL5SR5O8q1SyuHDKg4AAGAiBgo4tdaf1FqfU2v9dv/ne5K8Pcl9Sf5g9PSllFNKKctLKctXrVo1rQUDAACMZ9Ln4NRaVyf5QZIjxnhuaa11fq11/ty5c6dSHwAAwMAGCjillB1KKVuP8dQjSbac3pIAAAAmZ9AenP+Z5LXdhn7geU6S70x3UQAAAJMxkUPU3lNK2T1JSilbJjknydwkHxxGYQAAABM1Z8Dp/ijJbyS5tJSSJDsnuT7JMbXWK4ZUWxOW3XTXhOe5es2KJMnpiw6Y7nIAAKBpAwWcWusPkrxjyLUAAABMyaRHUQMAAJhtBBwAAKAZAg4AANAMAQcAAGiGgAMAADRDwAEAAJoh4AAAAM0QcAAAgGYIOAAAQDMEHAAAoBkCDgAA0AwBBwAAaMacmS6Axzvi1qW9B1fsNLEZFy6e/mIAAGATogcHAABohoADAAA0Q8ABAACaIeAAAADNEHAAAIBmCDgAAEAzBBwAAKAZAg4AANAMAQcAAGiGgAMAADRDwAEAAJoh4AAAAM0QcAAAgGYIOAAAQDMEHAAAoBkCDgAA0AwBBwAAaIaAAwAANEPAAQAAmiHgAAAAzRBwAACAZgg4AABAMwQcAACgGXNmugDGt+ymuyY0/dVrViRJTl90wDDKAQCAWU8PDgAA0AwBBwAAaIaAAwAANEPAAQAAmiHgAAAAzRBwAACAZgg4AABAMwQcAACgGQIOAADQDAEHAABohoADAAA0Q8ABAACaIeAAAADNEHAAAIBmCDgAAEAzBBwAAKAZAg4AANAMAQcAAGiGgAMAADRDwAEAAJoh4AAAAM2YM9MFMH2OuHVp78EVOw0+08LFwykGAABmwKR6cEop/1hKqaWUvaa5HgAAgEmbcMAppbw2yVFDqAUAAGBKJhRwSilbJzk7ycXDKQcAAGDyJtqD81tJrunfAAAAZpWBA04pZcck70nirHQAAGBWmkgPzvuSfKHWesuwigEAAJiKgYaJLqXsn+R1SQ4ccPpTkpySJHvuueekiwMAAJiIQXtwliQ5u9Z69yAT11qX1lrn11rnz507d/LVAQAATMAGe3BKKUcneXaS44ZfDgAAwOQNcojaoiRbJrmmlDLStlv//uJSykNJfq/WauhoAABgRm0w4NRa35feAANrlVI+kOT9SV5Za715KJUBAABM0ESvgwMAADBrTSjglFJeWUr5bpK395su7v8MAAAw4wYaJnpE/zwb59rMcstuumvgaa9es2Lt49MXHTCMcgAAYKNxiBoAANAMAQcAAGiGgAMAADRDwAEAAJoh4AAAAM0QcAAAgGYIOAAAQDMEHAAAoBkCDgAA0AwBBwAAaIaAAwAANEPAAQAAmiHgAAAAzZgz0wUws464deljP1yx0+AzLlw8/cUAAMAU6cEBAACaIeAAAADNEHAAAIBmCDgAAEAzBBwAAKAZAg4AANAMAQcAAGiGgAMAADRDwAEAAJoh4AAAAM0QcAAAgGYIOAAAQDMEHAAAoBkCDgAA0AwBBwAAaIaAAwAANGPOTBfA7LHsprsGnvbqNSvWPj590QHDKAcAACZMDw4AANAMAQcAAGiGgAMAADRDwAEAAJoh4AAAAM0QcAAAgGYIOAAAQDMEHAAAoBkCDgAA0Iw5M10Am6Yjbl362A9X7DTYTAsXD6cYAADo04MDAAA0Q8ABAACaIeAAAADNEHAAAIBmCDgAAEAzBBwAAKAZAg4AANAMAQcAAGiGgAMAADRDwAEAAJoh4AAAAM0QcAAAgGYIOAAAQDMEHAAAoBlzZroANn3LbrproOmuXrNinZ9PX3TAMMoBAGAzpgcHAABohoADAAA0Q8ABAACaIeAAAADN2OAgA6WUfZOcmmRhv+lJSVYmObvW+tUh1gYAADAhg/TgvCLJ8UmOq7UelmRekmVJ/raU8uJhFgcAADARgwSc25J8oNb6r0lSa300yR/05/2vQ6wNAABgQjZ4iFqt9W/GaH5y/37V9JYDAAAweRMeZKCUskeSTyT5Tv8eAABgVhg44JRS9i2l/GuSnybZMsmxtdZ7xpn2lFLK8lLK8lWrdPIAAAAbx8ABp9b6b7XW/ZLskGRFku+VUo4aZ9qltdb5tdb5c+fOnaZSAQAA1m/Ch6j1e21OT2+o6E9Oe0UAAACTNMh1cLZN8kCttY601VprKeUHSX69lPKEWuuDwyySNhxx69J1G67YabAZFy6e/mIAAGjSID04lyQ5Yoz2vZLck+Sh6SwIAABgsgY9RO2DpZSdkqT0/L9JDk/yJ92eHQAAgJm0wUPUkpyZ5G1J/qGUsibJNknuSnJCkguGWBsAAMCEDHKhz6uSXLURagEAAJiSCY+iBgAAMFsJOAAAQDMEHAAAoBkCDgAA0AwBBwAAaMYgw0TDUCy76a6Bprt6zYrHtZ2+6IDpLgcAgAbowQEAAJoh4AAAAM0QcAAAgGYIOAAAQDMEHAAAoBkCDgAA0AwBBwAAaIaAAwAANEPAAQAAmiHgAAAAzRBwAACAZsyZ6QJgQ464denjG6/YacMzLlw8/cUAADCr6cEBAACaIeAAAADNEHAAAIBmCDgAAEAzBBwAAKAZRlFjk7Tsprs2OM3Va1Y8ru30RQcMoxwAAGYJPTgAAEAzBBwAAKAZAg4AANAMAQcAAGiGgAMAADRDwAEAAJoh4AAAAM0QcAAAgGYIOAAAQDMEHAAAoBkCDgAA0AwBBwAAaIaAAwAANGPOTBcAw3LErUsf33jFTuufaeHi4RQDAMBGoQcHAABohoADAAA0wyFqbFaW3XTXep+/es2KMdtPX3TAMMoBAGCa6cEBAACaIeAAAADNEHAAAIBmCDgAAEAzBBwAAKAZAg4AANAMAQcAAGiGgAMAADRDwAEAAJoh4AAAAM0QcAAAgGYIOAAAQDMEHAAAoBkCDgAA0AwBBwAAaMacmS4AZpMjbl069hNX7LT+GRcunv5iAACYMD04AABAMwQcAACgGQIOAADQjA2eg1NKOTTJbyU5KsmaJFsm+fskH661rhpqdTBLLLvprvU+f/WaFWO2n77ogGGUAwDAOAbpwbkwyY5J5tdan5NkUZKXJrmqlLLtMIsDAACYiEEPUTuj1npfktRab0tyTpL9k7xyWIUBAABM1CDDRB9ca31oVNvt/funTnM9AAAAk7bBHpwxwk2SHJCkJvnGtFcEAAAwSRMeRa2UsmWStyb5XK11zDOrSymnlFKWl1KWr1plHAIAAGDjmMww0f8jycNJ3jneBLXWpbXW+bXW+XPnzp1sbQAAABMyyDk4a5VS3pzkdUkWjAw6AAAAMFsM3INTSjkxybuT/HKt9Y7hlQQAADA5AwWcUsoJSc5Ickyt9Wf9tleVUk4ZZnEAAAATscFD1Eopb0zyZ+mde3NMKWXkqaOT/PvwSgMAAJiYQc7B+dMk26R3cc/RPji95QAAAEzeBgNOrXXHjVEIAADAVE1mmGgAAIBZScABAACaMaHr4ABjO+LWpWM/ccVO659x4eLpLwYAYDMm4MAQLbvprvU+f/WaFWO2n77ogGGUAwDQPIeoAQAAzRBwAACAZgg4AABAMwQcAACgGQIOAADQDAEHAABohoADAAA0Q8ABAACa4UKfMIOOuHXp2E9csdP4My1cPJxiAAAaIODALLTsprvGfe7qNSvWO+/piw6Y7nIAADYZDlEDAACaIeAAAADNEHAAAIBmCDgAAEAzBBwAAKAZAg4AANAMAQcAAGiGgAMAADRDwAEAAJoh4AAAAM0QcAAAgGYIOAAAQDPmzHQBwMQccevS9U9wxU5jty9cPP3FAADMMnpwAACAZgg4AABAMxyiBo1ZdtNdY7ZfvWbFeuc7fdEBwygHAGCj0oMDAAA0Q8ABAACaIeAAAADNEHAAAIBmCDgAAEAzBBwAAKAZAg4AANAMAQcAAGiGgAMAADRjzkwXAGwcR9y6dL3PL/vc2O1X73nKeuc7fdEBky0JAGDa6cEBAACaIeAAAADNEHAAAIBmCDgAAEAzBBwAAKAZAg4AANAMAQcAAGiGgAMAADRDwAEAAJoh4AAAAM0QcAAAgGYIOAAAQDPmzHQBwOx2xK1L1/v8ss89vu3qPU/Z4HJPX3TAZEsCABiXHhwAAKAZAg4AANAMAQcAAGiGgAMAADRDwAEAAJoxcMAppexeSrm0lFKHWRAAAMBkDRRwSim/lmRZkn2HWw4AAMDkDXodnDOSLEpyZpL9hlcO0IINXTsnSXLFTo9vW7h4+osBADYrgwacF9Va15RShloMsPlYdtNdj2u7es2KDc7nAqEAwPoMdIharXXNsAsBAACYKqOoAQAAzRBwAACAZgwl4JRSTimlLC+lLF+1atUwVgEAAPA4gw4yMCG11qVJlibJ/PnzXTcHmDYfv2zDAxGMxwAFANC+oQQcgMkYaHjpMVy95ynTXAkAsKlyDg4AANAMAQcAAGjGQIeolVLOSbIoyZ79n7/bf+r5tdaHhlMaAADAxAwUcGqt7xl2IQAAAFNlkAFgszHZEdiMvgYAmw7n4AAAAM0QcAAAgGYIOAAAQDMEHAAAoBkCDgAA0AwBBwAAaIZhooFN3hG3Lp3wPFfvecoQKgEAZpoeHAAAoBl6cAA2wAVCAWDTIeAAm6XJHNaWOLQNAGY7h6gBAADNEHAAAIBmCDgAAEAzBBwAAKAZBhkAGBKjrwHAxqcHBwAAaIaAAwAANMMhagAT4Po5ADC7CTgAs4xzdwBg8hyiBgAANEPAAQAAmuEQNYCNYDLn7jhvBwAmTg8OAADQDAEHAABohoADAAA0wzk4ALPUhM/buWKn3v3CxdNfDABsIgQcgEYsu+muJMnVayZ+HR3X0AGgFQ5RAwAAmqEHB4B8/LKJ9/oken4AmH304AAAAM0QcAAAgGYIOAAAQDMEHAAAoBkGGQBozISvn5Pk6j1PmdS6DE4AwGyjBwcAAGiGHhwAJtXrk+j5AWD20YMDAAA0Q8ABAACaIeAAAADNcA4OAJO2sc/dAYAN0YMDAAA0Q8ABAACaIeAAAADNcA4OAJsM188BYEMEHAA2uskMTjCVgQkmG4wS4QhgU+MQNQAAoBl6cADYJMzUkNQOiwPYtOjBAQAAmiHgAAAAzXCIGgBNc2gbwOZFDw4AANAMPTgAMIaNPZQ1ANNDwAGAaTIdh8NN5Zo9k+GQOKA1DlEDAACaIeAAAADNcIgaAMywmRrpDaBFAg4AbKKmYyCEqZzz4/wdYDYScACASXGtH2A2EnAAYDMy2cPhJsthdMDGNlDAKaXskuTjSeb3m36Q5J211p8OqzAAoE2GwgaGaYMBp5SydZLLkqxIclCSmuTPk1xRSnlurfXe4ZYIAGyqXDAV2NgG6cF5U5KDk/xqrXVNkpRSzkhyW5JTk5wzvPIAgM3NdB9Gt+xz4z8328KU3iaYukECzmuT3FprvWmkodb6s1LKD/vPCTgAwCbJEN3QnkECzsHpHZ422o+TvGR6ywEAmP2GNVjDWL1NszVM6W1ithok4Oyc5NtjtN+TZLtSyra11tXTWxYAAMnGH/luUOs79G/YJhL61gaxKz4yuZUtXDy5+ZgxQxkmupRySpKRPe/eUsqPhrEeZtzOSe6c6SKgwz7JbGS/ZLZpYJ/8o4GnfNeU1/V7U14CA9k5yTOmY0GDBJw7kzxpjPYnJ7l/rN6bWuvSJLPz3w1Mm1LK8lrr/A1PCRuHfZLZyH7JbGOfZDbq75d7Tceythhgmu8nGWtle6d3PRwAAIBZYZCA86Ukzyil7DXSUErZNcmBSf7PkOoCAACYsEECzrnp9dQsKaXMKaVskeTs9EZR+9QQa2P2cxgis419ktnIfslsY59kNpq2/bLUWjc8Ua/H5uNJ5iepSa5N8s5a60+mqxAAAICpGijgAAAAbAoGOUQNYJNXSvn9UkotpZw807UAwOailLJ7KeXSUspG61URcFhHKWWXUspfllJ+1L/971LK0waYb/dSygdLKd8vpVxbSrmhlPKlUspzNkbdtGuy++SoZTwt03EpBOib6n5ZSjmklPKVUsp3+p+XPyqlfHSYNdO2qeyT/b/hn+3vi98vpVxXSvm9UspWw66btpVSfi3JsiT7TnL+d5ZSftjfL79TSjl2kPkEHNYqpWyd5LIkWyc5KMmzktyX5IpSyhM3MPv7k7w+ya/UWp+d5NAkjyT5lpDDZE1xn+z6gySXT3+FbI6mul+WUl6Y5JIkH621Pq/WOi/JnyR53fCqpmVT2Sf7g0ddnOSIJC+qtR6c5IQk/yPJR4ZZN5uFM5IsSnLVRGcspfxukv+e5NX9/fKMJH9dSnnFhuYVcOh6U5KDk5xRa11Ta30kvZ1pnySnDjD/R0cGnqi1PpDkd5Nsm+SUIdVL+6a6T6aUcliSFyX506FVyeZm0vtlKaUk+VySj9dau3/wl25oXliPqXxWzkvvn5Kfq7XelSS11n9J8n+TvHFoFbO5eFGt9caJzlRKeUp6IfuTtdZ/S5Ja62Xp7Zd/uKH5BRy6Xpvk1lrrTSMNtdafJflh/7n1eUeSPx/Vdnv//qnTViGbm6nskyP+KMmZSR6c/vLYTE1lvzwqvS+Uf9dtrLU+XGu9ZLoLZbMxlX1yTf9+zqj2OUm2nLYK2SzVWtdseKoxvTzJdkmuGNV+eZJnlVLmrW9mAYeug9O7vtFoP06y3sPM+v8xenRU8wH9+yunXhqbqUnvk0nSP1Z32yR/Nb1lsZmbyn75wv79Dv1zcK7rH1v++6WUbae1SjYnU/n7vSLJBUl+Y+Si7qWUX07vsCI938yUg/v3o/frH496fkwCDl07J/nFGO33JNluEn98T0lyXZLzp1oYm61J75P9k2OXJHl3NR4+02sqn5VP799/MclZtdaDkpyY5OQkX5nOItmsTPXv95vSOw/nxlLK7Um+nN71Dj88rVXC4Hbu34/er+/p3++0vpkFHIailPKSJMcleV2t1aFBzIRTk1xXa/3mTBcCHdv07z9Xa/3nJKm1fi+9ML6olPLiGauMzVIpZZv0DgN6fpK9aq2/lGRBksWllDNnsjaYLAGHrjuTPGmM9icnub/WunqQhZRSDknyF0leU2v94TTWx+ZnUvtk/+TExemdZAvTbSqflSP/jfzuqPZ/6d8fPrXS2ExNZZ98S3rnhr2n1npbktRav5PeidwfLqUcOs21wiDu7N+P3q+f3L+/a30zCzh0fT/JXmO0753kB4MsoJRycHpd28fXWv9p2ipjczXZffKI9E6c/etSyndLKd9N8tn+cx/qt71vOgtlszKVz8ob+vej//4+Mk47DGIq++TIOTqjR7pakaRE6GZmfL9/v9eo9r1HPT8mH6R0fSnJM0ZOMkySUsquSQ5M8n+6E5ZSdu2Pnd9tOzi9Y8hPHDksqH/xsM8Mu3CaNal9stZ6aa316bXWQ0duSd7Wn/R9/bYPbZRXQIum8ll5cXphZvQJss/u318z7dWyOZjKPnlH/37PUct8Rv9+vf8ph+lQStmpfz2nEZcmuT+9wyW7Fib5Ya31hqyHgEPXuen9p2dJKWVO/wPw7PRGrPjUyESllBelNwT0Jzptz0ny9SRfS7JXKeWEUsoJ6Z2H88yN9gpozbmZ5D4JQ3RuJrlf9q8V9idJfquUsn9/uj2SvDfJZbXW0UOiwiDOzeQ/K89N79DJ3y+lPKk/3Z5JfifJTeldlBaGppSyd5Lb0hlopdb68yQfTu+zcp/+dMckeVl6++Z6jR7znM1YrfWhUsqiJB9Pb+z8muTaJL9ca723M+m9Se5O8u+dtg+mN+LFb/RvXf8wtKJp2hT3ySRJKWWX9C4MNnI17w+VUt6Z5G211uVDLJ9GTcN++Z70ji+/uJTySJKt0vsv+/uHXTttmso+WWv9cSnl+Uk+kOSaUspD6e2TX0vy4UHPv4WxlFLOSW/I8T37P3+3/9Tza60P9R+vTvIfeez6iUmSWuvZpZQHkvxdKWVNer3f/88g1wwrRk8FAABa4RA1AACgGQIOAADQDAEHAABohoADAAA0Q8ABAACaIeAAAADNEHAAAIBmCDgAAEAzBBwAAKAZAg4AANCM/x/q9+PWhgXpcAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 1008x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "heights11, _, _ = plt.hist(train_events[0].numpy(), bins=50, alpha=0.5, label=\"sigma1\", density=True)\n",
    "heights12, _, _ = plt.hist(train_events[1].numpy(), bins=50, alpha=0.5, label=\"sigma2\", density=True)\n",
    "plt.title(\"Ground truth events distribution (Torch)\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "yellow-norfolk",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Training Loop...\n",
      "[0/100000]\tLoss_D: 1.3846\tLoss_G: 0.7052\n",
      "[50/100000]\tLoss_D: 1.3872\tLoss_G: 0.6972\n",
      "[100/100000]\tLoss_D: 1.3877\tLoss_G: 0.6869\n",
      "[150/100000]\tLoss_D: 1.3880\tLoss_G: 0.6944\n",
      "[200/100000]\tLoss_D: 1.3859\tLoss_G: 0.6970\n",
      "[250/100000]\tLoss_D: 1.3861\tLoss_G: 0.6812\n",
      "[300/100000]\tLoss_D: 1.3881\tLoss_G: 0.7013\n",
      "[350/100000]\tLoss_D: 1.3870\tLoss_G: 0.6884\n",
      "[400/100000]\tLoss_D: 1.3864\tLoss_G: 0.6853\n",
      "[450/100000]\tLoss_D: 1.3857\tLoss_G: 0.7027\n",
      "[500/100000]\tLoss_D: 1.3863\tLoss_G: 0.6949\n",
      "[550/100000]\tLoss_D: 1.3863\tLoss_G: 0.6872\n",
      "[600/100000]\tLoss_D: 1.3870\tLoss_G: 0.6960\n",
      "[650/100000]\tLoss_D: 1.3860\tLoss_G: 0.6903\n",
      "[700/100000]\tLoss_D: 1.3856\tLoss_G: 0.6889\n",
      "[750/100000]\tLoss_D: 1.3853\tLoss_G: 0.6863\n",
      "[800/100000]\tLoss_D: 1.3858\tLoss_G: 0.7071\n",
      "[850/100000]\tLoss_D: 1.3845\tLoss_G: 0.6819\n",
      "[900/100000]\tLoss_D: 1.3883\tLoss_G: 0.7049\n",
      "[950/100000]\tLoss_D: 1.3863\tLoss_G: 0.6822\n",
      "[1000/100000]\tLoss_D: 1.3851\tLoss_G: 0.7091\n",
      "[1050/100000]\tLoss_D: 1.3848\tLoss_G: 0.6845\n",
      "[1100/100000]\tLoss_D: 1.3888\tLoss_G: 0.7010\n",
      "[1150/100000]\tLoss_D: 1.3861\tLoss_G: 0.6892\n",
      "[1200/100000]\tLoss_D: 1.3903\tLoss_G: 0.6894\n",
      "[1250/100000]\tLoss_D: 1.3856\tLoss_G: 0.6907\n",
      "[1300/100000]\tLoss_D: 1.3882\tLoss_G: 0.7084\n",
      "[1350/100000]\tLoss_D: 1.3881\tLoss_G: 0.6838\n",
      "[1400/100000]\tLoss_D: 1.3870\tLoss_G: 0.7002\n",
      "[1450/100000]\tLoss_D: 1.3861\tLoss_G: 0.6804\n",
      "[1500/100000]\tLoss_D: 1.3856\tLoss_G: 0.7026\n",
      "[1550/100000]\tLoss_D: 1.3861\tLoss_G: 0.6923\n",
      "[1600/100000]\tLoss_D: 1.3859\tLoss_G: 0.6879\n",
      "[1650/100000]\tLoss_D: 1.3850\tLoss_G: 0.7064\n",
      "[1700/100000]\tLoss_D: 1.3855\tLoss_G: 0.6886\n",
      "[1750/100000]\tLoss_D: 1.3861\tLoss_G: 0.6925\n",
      "[1800/100000]\tLoss_D: 1.3875\tLoss_G: 0.7014\n",
      "[1850/100000]\tLoss_D: 1.3863\tLoss_G: 0.6883\n",
      "[1900/100000]\tLoss_D: 1.3845\tLoss_G: 0.7011\n",
      "[1950/100000]\tLoss_D: 1.3880\tLoss_G: 0.6866\n",
      "[2000/100000]\tLoss_D: 1.3853\tLoss_G: 0.6981\n",
      "[2050/100000]\tLoss_D: 1.3862\tLoss_G: 0.6848\n",
      "[2100/100000]\tLoss_D: 1.3862\tLoss_G: 0.7020\n",
      "[2150/100000]\tLoss_D: 1.3840\tLoss_G: 0.6842\n",
      "[2200/100000]\tLoss_D: 1.3865\tLoss_G: 0.6960\n",
      "[2250/100000]\tLoss_D: 1.3864\tLoss_G: 0.6930\n",
      "[2300/100000]\tLoss_D: 1.3872\tLoss_G: 0.6903\n",
      "[2350/100000]\tLoss_D: 1.3875\tLoss_G: 0.6956\n",
      "[2400/100000]\tLoss_D: 1.3863\tLoss_G: 0.6870\n",
      "[2450/100000]\tLoss_D: 1.3858\tLoss_G: 0.6976\n",
      "[2500/100000]\tLoss_D: 1.3862\tLoss_G: 0.6934\n",
      "[2550/100000]\tLoss_D: 1.3865\tLoss_G: 0.6913\n",
      "[2600/100000]\tLoss_D: 1.3861\tLoss_G: 0.6963\n",
      "[2650/100000]\tLoss_D: 1.3866\tLoss_G: 0.6889\n",
      "[2700/100000]\tLoss_D: 1.3863\tLoss_G: 0.6937\n",
      "[2750/100000]\tLoss_D: 1.3862\tLoss_G: 0.6947\n",
      "[2800/100000]\tLoss_D: 1.3868\tLoss_G: 0.6864\n",
      "[2850/100000]\tLoss_D: 1.3862\tLoss_G: 0.6986\n",
      "[2900/100000]\tLoss_D: 1.3863\tLoss_G: 0.6924\n",
      "[2950/100000]\tLoss_D: 1.3862\tLoss_G: 0.6938\n",
      "[3000/100000]\tLoss_D: 1.3865\tLoss_G: 0.6969\n",
      "[3050/100000]\tLoss_D: 1.3877\tLoss_G: 0.6838\n",
      "[3100/100000]\tLoss_D: 1.3866\tLoss_G: 0.7005\n",
      "[3150/100000]\tLoss_D: 1.3872\tLoss_G: 0.6877\n",
      "[3200/100000]\tLoss_D: 1.3867\tLoss_G: 0.6974\n",
      "[3250/100000]\tLoss_D: 1.3868\tLoss_G: 0.6908\n",
      "[3300/100000]\tLoss_D: 1.3864\tLoss_G: 0.6950\n",
      "[3350/100000]\tLoss_D: 1.3860\tLoss_G: 0.6930\n",
      "[3400/100000]\tLoss_D: 1.3866\tLoss_G: 0.6960\n",
      "[3450/100000]\tLoss_D: 1.3867\tLoss_G: 0.6916\n",
      "[3500/100000]\tLoss_D: 1.3831\tLoss_G: 0.7072\n",
      "[3550/100000]\tLoss_D: 1.3863\tLoss_G: 0.6801\n",
      "[3600/100000]\tLoss_D: 1.3861\tLoss_G: 0.7037\n",
      "[3650/100000]\tLoss_D: 1.3853\tLoss_G: 0.6874\n",
      "[3700/100000]\tLoss_D: 1.3854\tLoss_G: 0.6976\n",
      "[3750/100000]\tLoss_D: 1.3868\tLoss_G: 0.6942\n",
      "[3800/100000]\tLoss_D: 1.3866\tLoss_G: 0.6916\n",
      "[3850/100000]\tLoss_D: 1.3864\tLoss_G: 0.6915\n",
      "[3900/100000]\tLoss_D: 1.3872\tLoss_G: 0.6931\n",
      "[3950/100000]\tLoss_D: 1.3841\tLoss_G: 0.7029\n",
      "[4000/100000]\tLoss_D: 1.3861\tLoss_G: 0.6928\n",
      "[4050/100000]\tLoss_D: 1.3894\tLoss_G: 0.6840\n",
      "[4100/100000]\tLoss_D: 1.3865\tLoss_G: 0.7164\n",
      "[4150/100000]\tLoss_D: 1.3860\tLoss_G: 0.6899\n",
      "[4200/100000]\tLoss_D: 1.3870\tLoss_G: 0.6893\n",
      "[4250/100000]\tLoss_D: 1.3858\tLoss_G: 0.7034\n",
      "[4300/100000]\tLoss_D: 1.3862\tLoss_G: 0.6944\n",
      "[4350/100000]\tLoss_D: 1.3855\tLoss_G: 0.6896\n",
      "[4400/100000]\tLoss_D: 1.3866\tLoss_G: 0.6905\n",
      "[4450/100000]\tLoss_D: 1.3860\tLoss_G: 0.6982\n",
      "[4500/100000]\tLoss_D: 1.3862\tLoss_G: 0.6931\n",
      "[4550/100000]\tLoss_D: 1.3862\tLoss_G: 0.6896\n",
      "[4600/100000]\tLoss_D: 1.3860\tLoss_G: 0.6932\n",
      "[4650/100000]\tLoss_D: 1.3867\tLoss_G: 0.6959\n",
      "[4700/100000]\tLoss_D: 1.3865\tLoss_G: 0.6919\n",
      "[4750/100000]\tLoss_D: 1.3864\tLoss_G: 0.6914\n",
      "[4800/100000]\tLoss_D: 1.3859\tLoss_G: 0.6956\n",
      "[4850/100000]\tLoss_D: 1.3862\tLoss_G: 0.6931\n",
      "[4900/100000]\tLoss_D: 1.3872\tLoss_G: 0.6909\n",
      "[4950/100000]\tLoss_D: 1.3863\tLoss_G: 0.6962\n",
      "[5000/100000]\tLoss_D: 1.3863\tLoss_G: 0.6930\n",
      "[5050/100000]\tLoss_D: 1.3865\tLoss_G: 0.6912\n",
      "[5100/100000]\tLoss_D: 1.3863\tLoss_G: 0.6947\n",
      "[5150/100000]\tLoss_D: 1.3862\tLoss_G: 0.6933\n",
      "[5200/100000]\tLoss_D: 1.3864\tLoss_G: 0.6919\n",
      "[5250/100000]\tLoss_D: 1.3863\tLoss_G: 0.6930\n",
      "[5300/100000]\tLoss_D: 1.3863\tLoss_G: 0.6948\n",
      "[5350/100000]\tLoss_D: 1.3863\tLoss_G: 0.6926\n",
      "[5400/100000]\tLoss_D: 1.3863\tLoss_G: 0.6932\n",
      "[5450/100000]\tLoss_D: 1.3864\tLoss_G: 0.6941\n",
      "[5500/100000]\tLoss_D: 1.3860\tLoss_G: 0.6923\n",
      "[5550/100000]\tLoss_D: 1.3861\tLoss_G: 0.6942\n",
      "[5600/100000]\tLoss_D: 1.3863\tLoss_G: 0.6929\n",
      "[5650/100000]\tLoss_D: 1.3862\tLoss_G: 0.6919\n",
      "[5700/100000]\tLoss_D: 1.3860\tLoss_G: 0.6957\n",
      "[5750/100000]\tLoss_D: 1.3861\tLoss_G: 0.6916\n",
      "[5800/100000]\tLoss_D: 1.3864\tLoss_G: 0.6940\n",
      "[5850/100000]\tLoss_D: 1.3860\tLoss_G: 0.6933\n",
      "[5900/100000]\tLoss_D: 1.3865\tLoss_G: 0.6926\n",
      "[5950/100000]\tLoss_D: 1.3862\tLoss_G: 0.6940\n",
      "[6000/100000]\tLoss_D: 1.3862\tLoss_G: 0.6923\n",
      "[6050/100000]\tLoss_D: 1.3873\tLoss_G: 0.6964\n",
      "[6100/100000]\tLoss_D: 1.3857\tLoss_G: 0.6865\n",
      "[6150/100000]\tLoss_D: 1.3863\tLoss_G: 0.6961\n",
      "[6200/100000]\tLoss_D: 1.3863\tLoss_G: 0.6906\n",
      "[6250/100000]\tLoss_D: 1.3853\tLoss_G: 0.6945\n",
      "[6300/100000]\tLoss_D: 1.3862\tLoss_G: 0.6921\n",
      "[6350/100000]\tLoss_D: 1.3858\tLoss_G: 0.6937\n",
      "[6400/100000]\tLoss_D: 1.3866\tLoss_G: 0.6921\n",
      "[6450/100000]\tLoss_D: 1.3867\tLoss_G: 0.6929\n",
      "[6500/100000]\tLoss_D: 1.3873\tLoss_G: 0.6914\n",
      "[6550/100000]\tLoss_D: 1.3865\tLoss_G: 0.6935\n",
      "[6600/100000]\tLoss_D: 1.3909\tLoss_G: 0.6890\n",
      "[6650/100000]\tLoss_D: 1.3876\tLoss_G: 0.6888\n",
      "[6700/100000]\tLoss_D: 1.3864\tLoss_G: 0.6935\n",
      "[6750/100000]\tLoss_D: 1.3870\tLoss_G: 0.6946\n",
      "[6800/100000]\tLoss_D: 1.3860\tLoss_G: 0.6938\n",
      "[6850/100000]\tLoss_D: 1.3884\tLoss_G: 0.6852\n"
     ]
    }
   ],
   "source": [
    "# Training Loop\n",
    "\n",
    "# Lists to keep track of progress\n",
    "img_list = []\n",
    "G_losses = []\n",
    "D_losses = []\n",
    "iters = 0\n",
    "\n",
    "print(\"Starting Training Loop...\")\n",
    "# For each epoch\n",
    "for epoch in range(num_epochs):\n",
    "    # For each batch in the dataloader\n",
    "    \n",
    "    indices = np.random.randint(0, train_events.shape[1], 64)\n",
    "    data = np.transpose(train_events[:, indices])\n",
    "    noise = torch.randn(b_size, 50, device=device)\n",
    "    parmin = parmin.to(device)\n",
    "    parmax = parmax.to(device)\n",
    "\n",
    "    netD.zero_grad()\n",
    "    real_cpu = data.to(device)\n",
    "    b_size = real_cpu.size(0)\n",
    "    label = torch.full((b_size,), real_label, dtype=torch.float, device=device)\n",
    "\n",
    "    # Forward pass real batch through D\n",
    "    output = netD(real_cpu).view(-1)\n",
    "    errD_real = criterion(output, label)\n",
    "    errD_real.backward(retain_graph=True)\n",
    "\n",
    "    fake = netG(noise)\n",
    "    label.fill_(fake_label)\n",
    "    events, norm1, norm2 = wrapperGenerator(fake, parmin, parmax, 1)\n",
    "    events = torch.squeeze(events)\n",
    "    output = netD(events).view(-1)\n",
    "    errD_fake = criterion(output, label)\n",
    "    errD_fake.backward(retain_graph=True)\n",
    "    errD = errD_real + errD_fake\n",
    "    optimizerD.step()\n",
    "\n",
    "\n",
    "    # (2) Update G network: maximize log(D(G(z)))    \n",
    "    netG.zero_grad()\n",
    "    label.fill_(real_label)  \n",
    "    events, norm1, norm2 = wrapperGenerator(fake, parmin, parmax, 1)\n",
    "    events = torch.squeeze(events)\n",
    "    output = netD(events).view(-1)\n",
    "    errG = criterion(output, label)\n",
    "    errG.backward()\n",
    "    optimizerG.step()\n",
    "\n",
    "    # Output training stats\n",
    "    if iters % 50 == 0:\n",
    "        print('[%d/%d]\\tLoss_D: %.4f\\tLoss_G: %.4f'\n",
    "              % (epoch, num_epochs,\n",
    "                 errD.item(), errG.item()))\n",
    "\n",
    "    # Save Losses for plotting later\n",
    "    G_losses.append(errG.item())\n",
    "    D_losses.append(errD.item())\n",
    "\n",
    "    iters += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "liable-individual",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "thrown-activation",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
